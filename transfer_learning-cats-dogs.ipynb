{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer-learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmoroney/tfbook/blob/master/transfer_learning-cats-dogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ioLbtB3uGKPX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b84d0ec-8d60-4c69-ef63-25f470352971"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y23ucAFLoHop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib.request\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from shutil import copyfile\n",
        "\n",
        "\n",
        "data_url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\"\n",
        "data_file_name = \"catsdogs.zip\"\n",
        "download_dir = '/tmp/'\n",
        "urllib.request.urlretrieve(data_url, data_file_name)\n",
        "zip_ref = zipfile.ZipFile(data_file_name, 'r')\n",
        "zip_ref.extractall(download_dir)\n",
        "zip_ref.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwMoZHxWOynx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6291964b-2f3b-45fb-a05c-c20d6ed14223"
      },
      "source": [
        "print(len(os.listdir('/tmp/PetImages/Cat/')))\n",
        "print(len(os.listdir('/tmp/PetImages/Dog/')))\n",
        "\n",
        "# Expected Output:\n",
        "# 12501\n",
        "# 12501"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12501\n",
            "12501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qygIo4W5O1hQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    os.mkdir('/tmp/cats-v-dogs')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training')\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training/cats')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training/dogs')\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing/cats')\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing/dogs')\n",
        "except OSError:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M90EiIu0O314",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "44170e69-16f3-488a-a257-9e1521a97445"
      },
      "source": [
        "import random\n",
        "from shutil import copyfile\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "    files = []\n",
        "    for filename in os.listdir(SOURCE):\n",
        "        file = SOURCE + filename\n",
        "        if os.path.getsize(file) > 0:\n",
        "            files.append(filename)\n",
        "        else:\n",
        "            print(filename + \" is zero length, so ignoring.\")\n",
        "\n",
        "    training_length = int(len(files) * SPLIT_SIZE)\n",
        "    testing_length = int(len(files) - training_length)\n",
        "    shuffled_set = random.sample(files, len(files))\n",
        "    training_set = shuffled_set[0:training_length]\n",
        "    testing_set = shuffled_set[:testing_length]\n",
        "\n",
        "    for filename in training_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TRAINING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "    for filename in testing_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TESTING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "\n",
        "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
        "TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n",
        "TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\n",
        "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
        "TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n",
        "TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n",
        "\n",
        "split_size = .9\n",
        "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
        "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n",
        "\n",
        "# Expected output\n",
        "# 666.jpg is zero length, so ignoring\n",
        "# 11702.jpg is zero length, so ignoring"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "666.jpg is zero length, so ignoring.\n",
            "11702.jpg is zero length, so ignoring.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl8sQpM1O9xK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "686d49ab-60fa-48fb-cd0d-4b2ead156519"
      },
      "source": [
        "\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))\n",
        "\n",
        "# Expected output:\n",
        "# 11250\n",
        "# 11250\n",
        "# 1250\n",
        "# 1250"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11250\n",
            "11250\n",
            "1250\n",
            "1250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVO1l8vAPE14",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0bcdc4b3-02b4-43de-c76a-f3686aaef65d"
      },
      "source": [
        "\n",
        "TRAINING_DIR = \"/tmp/cats-v-dogs/training/\"\n",
        "# Experiment with your own parameters here to really try to drive it to 99.9% accuracy or better\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
        "                                                    batch_size=100,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))\n",
        "\n",
        "VALIDATION_DIR = \"/tmp/cats-v-dogs/testing/\"\n",
        "# Experiment with your own parameters here to really try to drive it to 99.9% accuracy or better\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
        "                                                              batch_size=100,\n",
        "                                                              class_mode='binary',\n",
        "                                                              target_size=(150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 22498 images belonging to 2 classes.\n",
        "# Found 2500 images belonging to 2 classes."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 22499 images belonging to 2 classes.\n",
            "Found 2500 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiPK1LlMOvm7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18c61719-595b-4717-b364-46868cd1668b"
      },
      "source": [
        "weights_url = \"https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "weights_file = \"inception_v3.h5\"\n",
        "urllib.request.urlretrieve(weights_url, weights_file)\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape=(150, 150, 3),\n",
        "                                include_top=False,\n",
        "                                weights=None)\n",
        "\n",
        "pre_trained_model.load_weights(weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nxUncKWPRhR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f19a26d2-d75c-4b56-deee-8b209d839864"
      },
      "source": [
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "#x = layers.Dropout(0.2)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input, x)\n",
        "\n",
        "model.compile(optimizer=RMSprop(lr=0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data=validation_generator,\n",
        "            epochs=20,\n",
        "            verbose=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 225 steps, validate for 25 steps\n",
            "Epoch 1/20\n",
            " 31/225 [===>..........................] - ETA: 2:33 - loss: 0.6113 - acc: 0.7302"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:784: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:784: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:784: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:784: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:784: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:784: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:784: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:802: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "225/225 [==============================] - 173s 770ms/step - loss: 0.3619 - acc: 0.8349 - val_loss: 0.2017 - val_acc: 0.9560\n",
            "Epoch 2/20\n",
            "225/225 [==============================] - 167s 743ms/step - loss: 0.2626 - acc: 0.8853 - val_loss: 0.2632 - val_acc: 0.9556\n",
            "Epoch 3/20\n",
            "225/225 [==============================] - 163s 725ms/step - loss: 0.2468 - acc: 0.8955 - val_loss: 0.2622 - val_acc: 0.9564\n",
            "Epoch 4/20\n",
            "225/225 [==============================] - 163s 723ms/step - loss: 0.2357 - acc: 0.9007 - val_loss: 0.3664 - val_acc: 0.9544\n",
            "Epoch 5/20\n",
            "225/225 [==============================] - 161s 716ms/step - loss: 0.2295 - acc: 0.9049 - val_loss: 0.3526 - val_acc: 0.9584\n",
            "Epoch 6/20\n",
            "225/225 [==============================] - 163s 724ms/step - loss: 0.2161 - acc: 0.9129 - val_loss: 0.4186 - val_acc: 0.9540\n",
            "Epoch 7/20\n",
            "225/225 [==============================] - 161s 716ms/step - loss: 0.2099 - acc: 0.9130 - val_loss: 0.5937 - val_acc: 0.9464\n",
            "Epoch 8/20\n",
            "225/225 [==============================] - 162s 719ms/step - loss: 0.2061 - acc: 0.9142 - val_loss: 0.3208 - val_acc: 0.9660\n",
            "Epoch 9/20\n",
            "225/225 [==============================] - 163s 727ms/step - loss: 0.2004 - acc: 0.9178 - val_loss: 0.4268 - val_acc: 0.9596\n",
            "Epoch 10/20\n",
            "225/225 [==============================] - 164s 729ms/step - loss: 0.2025 - acc: 0.9182 - val_loss: 0.3115 - val_acc: 0.9660\n",
            "Epoch 11/20\n",
            "225/225 [==============================] - 161s 718ms/step - loss: 0.2000 - acc: 0.9187 - val_loss: 0.6401 - val_acc: 0.9468\n",
            "Epoch 12/20\n",
            "225/225 [==============================] - 162s 719ms/step - loss: 0.1933 - acc: 0.9232 - val_loss: 0.4928 - val_acc: 0.9580\n",
            "Epoch 13/20\n",
            "225/225 [==============================] - 161s 714ms/step - loss: 0.1918 - acc: 0.9248 - val_loss: 0.6352 - val_acc: 0.9516\n",
            "Epoch 14/20\n",
            "225/225 [==============================] - 161s 714ms/step - loss: 0.1862 - acc: 0.9248 - val_loss: 0.4592 - val_acc: 0.9612\n",
            "Epoch 15/20\n",
            "225/225 [==============================] - 160s 713ms/step - loss: 0.1846 - acc: 0.9277 - val_loss: 0.3612 - val_acc: 0.9704\n",
            "Epoch 16/20\n",
            "225/225 [==============================] - 160s 711ms/step - loss: 0.1834 - acc: 0.9282 - val_loss: 0.4482 - val_acc: 0.9632\n",
            "Epoch 17/20\n",
            "225/225 [==============================] - 163s 724ms/step - loss: 0.1834 - acc: 0.9283 - val_loss: 0.5741 - val_acc: 0.9560\n",
            "Epoch 18/20\n",
            "225/225 [==============================] - 161s 718ms/step - loss: 0.1817 - acc: 0.9284 - val_loss: 0.5053 - val_acc: 0.9568\n",
            "Epoch 19/20\n",
            "225/225 [==============================] - 160s 712ms/step - loss: 0.1784 - acc: 0.9309 - val_loss: 0.4913 - val_acc: 0.9608\n",
            "Epoch 20/20\n",
            "225/225 [==============================] - 161s 716ms/step - loss: 0.1780 - acc: 0.9299 - val_loss: 0.4680 - val_acc: 0.9620\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erDopoQ5eNL7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "eb66a1f8-1ca0-462e-ea38-4358da793378"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['acc']\n",
        "val_acc=history.history['val_acc']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAccAAAEICAYAAAAqQj/TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}